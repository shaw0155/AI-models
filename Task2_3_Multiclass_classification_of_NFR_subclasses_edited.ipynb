{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaw0155/AI-models/blob/main/Task2_3_Multiclass_classification_of_NFR_subclasses_edited.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiclass Classification of non-functional requirement subclasses on Promise NFR dataset"
      ],
      "metadata": {
        "id": "zQlAOIMVJg5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook includes all code needed to train and evaluate a multiclass classifier for predicting a number of NFR subclasses on the Promise NFR dataset."
      ],
      "metadata": {
        "id": "MxPaynCQJy4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: some cells are hidden and only the title is shown. To display the code, double-click the cell to switch the display mode.\n"
      ],
      "metadata": {
        "id": "RQBBPihTJ-S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare\n",
        "Install required libraries and import"
      ],
      "metadata": {
        "id": "-djxLyuc-Opk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "#@title Install needed libraries {display-mode: \"form\"}\n",
        "!pip uninstall numpy\n",
        "!pip install numpy==1.23.5\n",
        "!pip install fastai==1.0.61 fastcore==1.3.29 fastprogress==1.0.3 pytorch-transformers==1.2.0 sklearn==0.0 spacy==3.6.1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.10\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy-1.23.5.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-742d56dc.3.20.so\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-1.23.5\n",
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "f342d7f19d084d79942454bd1aab3371"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastai==1.0.61 in /usr/local/lib/python3.10/dist-packages (1.0.61)\n",
            "Requirement already satisfied: fastcore==1.3.29 in /usr/local/lib/python3.10/dist-packages (1.3.29)\n",
            "Requirement already satisfied: fastprogress==1.0.3 in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: pytorch-transformers==1.2.0 in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.10/dist-packages (0.0)\n",
            "Requirement already satisfied: spacy==3.6.1 in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (4.12.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (3.7.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (2.10.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (1.23.5)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (7.352.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (2.1.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (24.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from fastai==1.0.61) (0.19.0+cu121)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastcore==1.3.29) (24.1.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers==1.2.0) (1.35.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers==1.2.0) (4.66.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers==1.2.0) (2024.5.15)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers==1.2.0) (0.1.99)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers==1.2.0) (0.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sklearn==0.0) (1.3.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (0.9.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (71.0.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.6.1) (3.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.6.1) (1.2.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.10.0->spacy==3.6.1) (0.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.6.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.6.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.6.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fastai==1.0.61) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fastai==1.0.61) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fastai==1.0.61) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fastai==1.0.61) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.6.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.6.1) (0.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->fastai==1.0.61) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->fastai==1.0.61) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->fastai==1.0.61) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->fastai==1.0.61) (2024.6.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy==3.6.1) (8.1.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->fastai==1.0.61) (2.6)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.10 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-transformers==1.2.0) (1.35.10)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-transformers==1.2.0) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-transformers==1.2.0) (0.10.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.6.1) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==1.0.61) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==1.0.61) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==1.0.61) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==1.0.61) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==1.0.61) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai==1.0.61) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai==1.0.61) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai==1.0.61) (2024.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers==1.2.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn==0.0) (3.5.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.6.1) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai==1.0.61) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->fastai==1.0.61) (1.3.0)\n"
          ]
        }
      ],
      "metadata": {
        "id": "Epk5taxa99eI",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "69a2b37f-df58-4a94-f8cd-d511a180be7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "#@title Import python packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "from pytorch_transformers import BertTokenizer, BertPreTrainedModel, BertModel, BertConfig\n",
        "from pytorch_transformers import AdamW\n",
        "\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from datetime import datetime"
      ],
      "outputs": [],
      "metadata": {
        "id": "Fr6bTWdl-XzF",
        "cellView": "form"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "#@title Check, if and what kind of GPU is used\n",
        "def get_memory_usage():\n",
        "    return torch.cuda.memory_allocated(device)/1000000\n",
        "\n",
        "def get_memory_usage_str():\n",
        "    return 'Memory usage: {:.2f} MB'.format(get_memory_usage())\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "if cuda_available:\n",
        "    curr_device = torch.cuda.current_device()\n",
        "    print(torch.cuda.get_device_name(curr_device))\n",
        "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
        "device"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "metadata": {
        "id": "Wtzha3q7QjjU",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee3041a-3fb0-4c29-f09c-d2e11448846d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define configuration used in this experiment run"
      ],
      "metadata": {
        "id": "mOKXVgJgGtYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create config and set hyperparameters.\n",
        "One can configure:\n",
        "\n",
        "\n",
        "*   BERT model to use (model_name)\n",
        "*   Learning Rate to use (max_lr)\n",
        "*   Momentum (moms)\n",
        "*   Epoch number for training (epochs)\n",
        "*   Badge size for training (bs)\n",
        "*   Weight decay for training (weight_decay)\n",
        "*   Maximal sequence length (max_seq_len)\n",
        "*   Train size used for both test/train and train/validation split (train_size)\n",
        "*   Loss function used for training (loss_func)\n",
        "*   The random seed used for shuffling, sampling and splitting (seed)\n",
        "*   Whether, or not to use early stopping (es)\n",
        "*   The minimal delta used to indicate early stopping (min_delta)\n",
        "*   The number of epochs that need to undergo this delta to early stop training (patience)\n",
        "*   The way of folding used for this experiment (either test/train split (No), ten-fold cross validation (TenFold), or project specific folding (ProjFold))\n",
        "\n",
        "\n",
        "Further one can configure, where to get the dataset from and where to save log, result and model files.\n",
        "By setting the classes Array one can decide which binary classifiers to train in evaluate in one experiment run.\n",
        "Two booleans are provided to decide whether to\n",
        "1. load data from Google Drive or download data from zenodo and to\n",
        "2. save the model file.\n",
        "\n"
      ],
      "metadata": {
        "id": "YkojV8t2KNOy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "\n",
        "class Fold(Enum):\n",
        "  No = 1\n",
        "  TenFold = 2\n",
        "  ProjFold = 3\n",
        "\n",
        "config = Config(\n",
        "    num_labels = 10, # will be set automatically afterwards\n",
        "    model_name=\"bert-base-cased\", # bert_base_uncased, bert_large_cased, bert_large_uncased\n",
        "    max_lr=2e-5, # default: 2e-5\n",
        "    moms=(0.8, 0.7), # default: (0.8, 0.7); alt.(0.95, 0.85)\n",
        "    epochs=16, # 10, 16, 32, 50\n",
        "    bs=16, # default: 16\n",
        "    weight_decay = 0.01,\n",
        "    max_seq_len=128, # 50, 128\n",
        "    train_size=0.75, # 0.8\n",
        "    loss_func=nn.CrossEntropyLoss(),\n",
        "    seed=904727489, #default: 904727489, 42 (as in Dalpiaz) or None\n",
        "    es = False, # True\n",
        "    min_delta = 0.01,\n",
        "    patience = 3,\n",
        "    fold = Fold.No, # Fold.No, Fold.TenFold, Fold.ProjFold\n",
        ")\n",
        "\n",
        "clazz = 'clazz'\n",
        "\n",
        "config_data = Config(\n",
        "    root_folder = '.', # where is the root folder? Keep it that way if you want to load from Google Drive\n",
        "    data_folder = '/', # where is the folder containing the datasets; relative to root\n",
        "    train_data = ['promise_nfr.csv'], # dataset file to use\n",
        "    label_column = clazz,\n",
        "    log_folder_name = '/log/',\n",
        "    log_file = clazz + '_' + Fold(config.fold).name + '_classifierPredictions_' + datetime.now().strftime('%Y%m%d-%H%M') + '.txt', # log-file name (make sure log folder exists)\n",
        "    result_file = clazz + '_' + Fold(config.fold).name + '_classifierResults_' + datetime.now().strftime('%Y%m%d-%H%M') + '.txt', # result-file name (make sure log folder exists)\n",
        "    model_path = '/models/', # where is the folder for the model(s); relative to the root\n",
        "    model_name = 'NoRBERT.pkl', # what is the model name?\n",
        "    gdrive_root_folder = '/content/drive/My Drive/Code/Task1_to_3_original_Promise_NFR_dataset/', # Set this to the Google Drive path. Starts with '/content/drive/' and then usually 'My Drive/*' for the files in your Drive\n",
        "\n",
        "    orig_data_set_zip = 'https://zenodo.org/record/8347866/files/NoRBERT_RE20_Paper65.zip', # link to the data set (on zenodo). DO NOT CHANGE!\n",
        "    orig_data_zip_name = 'NoRBERT_RE20_Paper65.zip', # DO NOT CHANGE\n",
        "    orig_data_file_in_zip = 'Code/Task1_to_3_original_Promise_NFR_dataset/promise_nfr.csv', # DO NOT CHANGE\n",
        "\n",
        "    # Project split to use, either p-fold (as in Dalpiaz) or loPo\n",
        "    #project_fold = [[3, 9, 11], [1, 5, 12], [6, 10, 13], [1, 8, 14], [3, 12, 15], [2, 5, 11], [6, 9, 14], [7, 8, 13], [2, 4, 15], [4, 7, 10] ], # p-fold\n",
        "    project_fold = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15] ], # loPo\n",
        "    #classes = ['US', 'SE', 'O', 'PE'], # mostFrequent\n",
        "    classes= ['A', 'FT', 'L', 'LF', 'MN', 'O', 'PE', 'PO', 'SC', 'SE', 'US'], # all\n",
        ")\n",
        "\n",
        "load_from_gdrive = False # True, if you want to use Google Drive; else, False\n",
        "save_model = False # True, if you want to use save the model file (make sure model folder exists)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "i0lgLyC6Gsnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To import the dataset, first we have to either load the data set from zenodo (and unzip the needed file) or connect to our Google drive (if data should be loaded from gdrive). To connect to our Google drive, we have to authenticate the access and mount the drive."
      ],
      "metadata": {
        "id": "SVU_viFX-ezy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "#@title Prepare data loading: Init loading from Google Drive, if set in config above. Else, download the data set from zenodo (using wget) {display-mode: \"form\"}\n",
        "if load_from_gdrive:\n",
        "    from google.colab import drive\n",
        "    # Connect to drive to load the corpus from there\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    config_data.root_folder = config_data.gdrive_root_folder\n",
        "else:\n",
        "    # If the file does not exist already, download the zip and extract the needed file\n",
        "    data_path = config_data.root_folder + config_data.data_folder + config_data.train_data[0]\n",
        "    data_file = Path(data_path)\n",
        "    if not data_file.exists():\n",
        "        !wget {config_data.orig_data_set_zip}\n",
        "        import zipfile\n",
        "        with zipfile.ZipFile(config_data.orig_data_zip_name) as z:\n",
        "            with open(data_path, 'wb') as f:\n",
        "                f.write(z.read(config_data.orig_data_file_in_zip))\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "OmGISBrhW-VJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "#@title Define logging functions and seed generation {display-mode: \"form\"}\n",
        "def initLog():\n",
        "    logfolder = config_data.root_folder + config_data.log_folder_name\n",
        "\n",
        "    if not os.path.isdir(logfolder):\n",
        "      print(\"Log folder does not exist, trying to create folder.\")\n",
        "      try:\n",
        "        os.mkdir(logfolder)\n",
        "      except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % logfolder)\n",
        "      else:\n",
        "        print (\"Successfully created the directory %s\" % logfolder)\n",
        "    logfile = logfolder + config_data.log_file\n",
        "    log_txt = datetime.now().strftime('%Y-%m-%d %H:%M') + ' ' + get_info()\n",
        "    with open(logfile, 'w') as log:\n",
        "        log.write(log_txt + '\\n')\n",
        "\n",
        "def logLine(line):\n",
        "    logfile = config_data.root_folder + config_data.log_folder_name  + config_data.log_file\n",
        "    with open(logfile, 'a') as log:\n",
        "        log.write(line + '\\n')\n",
        "\n",
        "def logResult(result):\n",
        "    logfile = config_data.root_folder + config_data.log_folder_name + config_data.result_file\n",
        "    with open(logfile, 'a') as log:\n",
        "        log.write(get_info() + '\\n')\n",
        "        log.write(result + '\\n')\n",
        "\n",
        "def get_info():\n",
        "     model_config = 'model: {}, max_lr: {}, epochs: {}, bs: {}, train_size: {}, weight decay: {},  Seed: {}, Data: {}, Column: {}, EarlyStopping: {}:{};pat:{}'.format(config.model_name, config.max_lr, config.epochs, config.bs, config.train_size, config.weight_decay, config.seed, config_data.train_data, config_data.label_column, config.es, config.min_delta, config.patience)\n",
        "     return model_config\n",
        "\n",
        "def set_seed(seed):\n",
        "    if seed is None:\n",
        "        seed = random.randint(0, 2**31)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    return seed\n",
        "\n",
        "set_seed(config.seed)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "904727489"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "id": "er1yzLHFQq1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120621bd-5325-40dd-c60b-d0d7a8f58df0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learner\n"
      ],
      "metadata": {
        "id": "Ptp6NhIC_FQb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "#@title Create proper tokenizer for our data (adapting FastAiTokenizer to use BertTokenizer) {display-mode: \"form\"}\n",
        "class FastAiBertTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=512, **kwargs):\n",
        "        self._pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str):\n",
        "        \"\"\"Limits the maximum sequence length. Prepend with [CLS] and append [SEP]\"\"\"\n",
        "        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "6anB63ppBAtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can create our own databunch using the tokenizer above. Notice we're passing the include_bos=False and include_eos=False options. This is to prevent fastai from adding its own SOS/EOS tokens that will interfere with BERT's SOS/EOS tokens.\n",
        "\n",
        "We can pass our own list of Preprocessors to the databunch."
      ],
      "metadata": {
        "id": "1G8rFbEEJWyu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "#@title Define Processors and Databunch {display-mode: \"form\"}\n",
        "class BertTokenizeProcessor(TokenizeProcessor):\n",
        "    \"\"\"Special Tokenizer, where we remove sos/eos tokens since we add that ourselves in the tokenizer.\"\"\"\n",
        "    def __init__(self, tokenizer):\n",
        "        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "class BertNumericalizeProcessor(NumericalizeProcessor):\n",
        "    \"\"\"Use a custom vocabulary to match the original BERT model.\"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, vocab=Vocab(list(bert_tok.vocab.keys())), **kwargs)\n",
        "\n",
        "def get_bert_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
        "    return [BertTokenizeProcessor(tokenizer=tokenizer),\n",
        "            NumericalizeProcessor(vocab=vocab)]\n",
        "\n",
        "class BertDataBunch(TextDataBunch):\n",
        "    @classmethod\n",
        "    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n",
        "              tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n",
        "              label_cols:IntsOrStrs=0, **kwargs) -> DataBunch:\n",
        "        \"Create a `TextDataBunch` from DataFrames.\"\n",
        "        p_kwargs, kwargs = split_kwargs_by_func(kwargs, get_bert_processor)\n",
        "        # use our custom processors while taking tokenizer and vocab as kwargs\n",
        "        processor = get_bert_processor(tokenizer=tokenizer, vocab=vocab, **p_kwargs)\n",
        "        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n",
        "        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n",
        "                      TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n",
        "        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_df(cols=label_cols, classes=classes)\n",
        "        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n",
        "        return src.databunch(**kwargs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "TNRRj6jIJrp2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "#@title Define own BertTextClassifier class{display-mode: \"form\"}\n",
        "class BertTextClassifier(BertPreTrainedModel):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        config = BertConfig.from_pretrained(model_name)\n",
        "        super(BertTextClassifier, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(model_name, config=config)\n",
        "\n",
        "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(self.config.hidden_size, num_labels)\n",
        "\n",
        "\n",
        "    def forward(self, tokens, labels=None, position_ids=None, token_type_ids=None, attention_mask=None, head_mask=None):\n",
        "        outputs = self.bert(tokens, position_ids=position_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, head_mask=head_mask)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(dropout_output)\n",
        "\n",
        "        activation = nn.Softmax(dim=1)\n",
        "        probs = activation(logits)\n",
        "\n",
        "        return logits"
      ],
      "outputs": [],
      "metadata": {
        "id": "he_PRt9Q3eUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "9Nk6mg3aLRYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset"
      ],
      "metadata": {
        "id": "IwxQFKykzpQq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "#@title Create the dictionary that contains the labels along with their indices. This is useful for evaluation and similar. {display-mode: \"form\"}\n",
        "def create_label_indices():\n",
        "    #prepare label\n",
        "    labels = config_data.classes\n",
        "    labels.append('Other')\n",
        "\n",
        "    #create dict\n",
        "    labelDict = dict()\n",
        "    for i in range (0, len(labels)):\n",
        "        labelDict[i] = labels[i]\n",
        "    return labelDict\n",
        "\n",
        "label_indices = create_label_indices()\n",
        "print(label_indices)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'A', 1: 'FT', 2: 'L', 3: 'LF', 4: 'MN', 5: 'O', 6: 'PE', 7: 'PO', 8: 'SC', 9: 'SE', 10: 'US', 11: 'Other'}\n"
          ]
        }
      ],
      "metadata": {
        "id": "TWP1X17N5tJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01613973-45a3-4d26-b59f-aae8273b271d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "#@title Define functions to load data {display-mode: \"form\"}\n",
        "def load_data(filename):\n",
        "    fpath = config_data.root_folder + config_data.data_folder + filename\n",
        "    print(fpath)\n",
        "    df = pd.read_csv(fpath, delimiter=';', header=0, encoding='utf8', names=['number', 'ProjectID', 'RequirementText', 'clazz', 'NFR', 'F', 'A', 'FT', 'L', 'LF', 'MN', 'O', 'PE', 'PO', 'SC', 'SE', 'US'])\n",
        "    df = df.dropna()\n",
        "    is_NFR = df['NFR']==1\n",
        "    df = df[is_NFR]\n",
        "\n",
        "    inv_map = {v: k for k, v in label_indices.items()}\n",
        "    df[config_data.label_column] = df[config_data.label_column].map(inv_map)\n",
        "    df[config_data.label_column].fillna(inv_map.get('Other'), inplace=True)\n",
        "    df[config_data.label_column]=df[config_data.label_column].astype(int)\n",
        "    df = df.loc[df[config_data.label_column] != 7]\n",
        "    df = df.reset_index()\n",
        "    return df\n",
        "\n",
        "def load_all_data(filenames):\n",
        "    df = load_data(filenames[0])\n",
        "    for i in range(1, len(filenames)):\n",
        "        df = df.append(load_data(filenames[i]))\n",
        "    return df\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "oeaTvNRTypP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "#@title Actually load dataset {display-mode: \"form\"}\n",
        "# load the train datasets\n",
        "df = load_all_data(config_data.train_data)\n",
        "input_col = 'RequirementText'\n",
        "\n",
        "# shuffle the dataset a bit and get the amount of classes\n",
        "df = df.sample(frac=1, axis=0, random_state = config.seed)\n",
        "config.num_labels = df[config_data.label_column].nunique()\n",
        "\n",
        "print(df.shape)\n",
        "print(df[config_data.label_column].value_counts())\n",
        "print(df['ProjectID'].value_counts())\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./promise_nfr.csv\n",
            "(369, 18)\n",
            "clazz\n",
            "10    67\n",
            "9     66\n",
            "5     62\n",
            "6     54\n",
            "3     38\n",
            "8     21\n",
            "0     21\n",
            "4     17\n",
            "2     13\n",
            "1     10\n",
            "Name: count, dtype: int64\n",
            "ProjectID\n",
            "8     73\n",
            "6     47\n",
            "5     37\n",
            "3     33\n",
            "4     30\n",
            "2     28\n",
            "12    22\n",
            "13    19\n",
            "14    16\n",
            "10    15\n",
            "11    13\n",
            "15    12\n",
            "9      8\n",
            "1      8\n",
            "7      8\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "metadata": {
        "id": "-6o6UU0tUYck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415ba839-04fe-450b-fce1-d345a21b24e3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "#@title Function to split dataframe according to train size {display-mode: \"form\"}\n",
        "def split_dataframe(df, train_size = 0.8, random_state = None):\n",
        "    # split data into training and validation set\n",
        "    df_trn, df_valid = train_test_split(df, stratify = df[config_data.label_column], train_size = train_size, random_state = random_state)\n",
        "    return df_trn, df_valid"
      ],
      "outputs": [],
      "metadata": {
        "id": "I4a0BVxnL_5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictor\n"
      ],
      "metadata": {
        "id": "SClv488eQC8B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "#@title Create a predictor class{display-mode: \"form\"}\n",
        "class Predictor:\n",
        "    def __init__(self, classifier):\n",
        "        self.classifier = classifier\n",
        "        self.classes = self.classifier.data.classes\n",
        "\n",
        "    def predict(self, text):\n",
        "        prediction = self.classifier.predict(text)\n",
        "        prediction_class = prediction[1]\n",
        "        return self.classes[prediction_class]"
      ],
      "outputs": [],
      "metadata": {
        "id": "qubb_Ka-C78O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and train the learner/classifier\n"
      ],
      "metadata": {
        "id": "zyVQS13d5Sft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "#@title Define functions to create databunch, learner and actual classifier{display-mode: \"form\"}\n",
        "def create_databunch(config, df_trn, df_valid):\n",
        "    bert_tok = BertTokenizer.from_pretrained(config.model_name,)\n",
        "    fastai_tokenizer = Tokenizer(tok_func=FastAiBertTokenizer(bert_tok, max_seq_len=config.max_seq_len), pre_rules=[], post_rules=[])\n",
        "    fastai_bert_vocab = Vocab(list(bert_tok.vocab.keys()))\n",
        "    return BertDataBunch.from_df(\".\",\n",
        "                   train_df=df_trn,\n",
        "                   valid_df=df_valid,\n",
        "                   tokenizer=fastai_tokenizer,\n",
        "                   vocab=fastai_bert_vocab,\n",
        "                   bs=config.bs,\n",
        "                   text_cols=input_col,\n",
        "                   label_cols=config_data.label_column,\n",
        "                   collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
        "              )\n",
        "\n",
        "\n",
        "def create_learner(config, databunch):\n",
        "    model = BertTextClassifier(config.model_name, config.num_labels)\n",
        "\n",
        "    optimizer = partial(AdamW)\n",
        "    if config.es:\n",
        "      learner = Learner(\n",
        "        databunch, model,\n",
        "        optimizer,\n",
        "        wd = config.weight_decay,\n",
        "        metrics=accuracy,\n",
        "        loss_func=config.loss_func, callback_fns=[partial(EarlyStoppingCallback, monitor='accuracy', min_delta=config.min_delta, patience=config.patience)]\n",
        "      )\n",
        "    else:\n",
        "      learner = Learner(\n",
        "        databunch, model,\n",
        "        optimizer,\n",
        "        wd = config.weight_decay,\n",
        "        metrics=accuracy,\n",
        "        loss_func=config.loss_func,\n",
        "      )\n",
        "\n",
        "    return learner\n",
        "\n",
        "# Create the classifier\n",
        "def create_classifier(config, df):\n",
        "  df_trn, df_valid = split_dataframe(df, train_size = config.train_size, random_state = config.seed)\n",
        "  databunch = create_databunch(config, df_trn, df_valid)\n",
        "\n",
        "  return create_learner(config, databunch)"
      ],
      "outputs": [],
      "metadata": {
        "id": "T83UogVz5XJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "#@title Define predict loop {display-mode: \"form\"}\n",
        "def predict_and_log_result(classifier, df_eval):\n",
        "  predictor = Predictor(classifier)\n",
        "  flat_predictions, flat_true_labels = [], []\n",
        "  column_index = df_eval.columns.get_loc(config_data.label_column)\n",
        "  for row in progress_bar(df_eval.itertuples(), total=len(df_eval)):\n",
        "      class_text = row.RequirementText\n",
        "      class_label = row[column_index+1]\n",
        "      flat_true_labels.append(class_label)\n",
        "      prediction = predictor.predict(class_text)\n",
        "      flat_predictions.append(prediction)\n",
        "\n",
        "      log_text = 'PID: {}, {}, {} -> {}'.format(row.ProjectID, class_text, label_indices.get(class_label), label_indices.get(prediction))\n",
        "      logLine(log_text)\n",
        "\n",
        "  # get labels in correct order\n",
        "  target_names = []\n",
        "  test_labels = unique_labels(flat_true_labels, flat_predictions)\n",
        "  test_labels = np.sort(test_labels)\n",
        "  for x in test_labels:\n",
        "    target_names.append(label_indices.get(x))\n",
        "\n",
        "  result = classification_report(flat_true_labels, flat_predictions, target_names=target_names, digits = 5)\n",
        "  logResult(result)\n",
        "  print(result)\n",
        "  return flat_predictions, flat_true_labels"
      ],
      "outputs": [],
      "metadata": {
        "id": "lCa-FApr9puF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "#@title Define train and test loop{display-mode: \"form\"}\n",
        "def train_and_predict(df_train, df_eval, overall_flat_predictions, overall_flat_true_labels, results):\n",
        "  classifier = create_classifier(config, df_train)\n",
        "  # Train the classifier on train set\n",
        "  print(classifier.fit_one_cycle(config.epochs, max_lr=config.max_lr, moms=config.moms, wd=config.weight_decay))\n",
        "  #Predict on test set\n",
        "  flat_predictions, flat_true_labels = predict_and_log_result(classifier, df_eval)\n",
        "  overall_flat_predictions.extend(flat_predictions)\n",
        "  overall_flat_true_labels.extend(flat_true_labels)\n",
        "  test_labels = df[config_data.label_column].unique()\n",
        "  test_labels = np.sort(test_labels)\n",
        "  results.extend(precision_recall_fscore_support(flat_true_labels, flat_predictions, labels = test_labels))\n",
        "  return classifier, overall_flat_predictions, overall_flat_true_labels, results"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ci927W84MPWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "#@title Decide how to fold and train the classifier {display-mode: \"form\"}\n",
        "overall_flat_predictions, overall_flat_true_labels, results = [], [], []\n",
        "initLog()\n",
        "if config.fold == Fold.TenFold:\n",
        "  skf = StratifiedKFold(n_splits=10)\n",
        "  fold_number = 1\n",
        "  for train, test in skf.split(df, df[config_data.label_column]):\n",
        "    df_train = df.iloc[train]\n",
        "    df_eval = df.iloc[test]\n",
        "    log_text = '/////////////////////// Fold: {} of {} /////////////////////////////'.format(fold_number,10)\n",
        "    logLine(log_text)\n",
        "    classifier, overall_flat_predictions, overall_flat_true_labels, results = train_and_predict(df_train, df_eval, overall_flat_predictions, overall_flat_true_labels, results)\n",
        "    fold_number = fold_number + 1\n",
        "elif config.fold == Fold.ProjFold:\n",
        "  for k in config_data.project_fold:\n",
        "    test = df.loc[df['ProjectID'].isin(k)].index\n",
        "    train = df.loc[~df['ProjectID'].isin(k)].index\n",
        "    df_train = df.loc[train]\n",
        "    df_eval = df.loc[test]\n",
        "    log_text = '/////////////////////// Test-Projects: {} /////////////////////////////'.format(k)\n",
        "    logLine(log_text)\n",
        "    classifier, overall_flat_predictions, overall_flat_true_labels, results = train_and_predict(df_train, df_eval, overall_flat_predictions, overall_flat_true_labels, results)\n",
        "else:\n",
        "  df_train, df_eval = train_test_split(df,stratify=df[config_data.label_column], train_size=config.train_size, random_state= config.seed)\n",
        "  classifier, overall_flat_predictions, overall_flat_true_labels, results = train_and_predict(df_train, df_eval, overall_flat_predictions, overall_flat_true_labels, results)\n",
        "\n",
        "get_memory_usage_str()\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/text/data.py:124: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  sort_idx = np.concatenate(np.random.permutation(ck_idx[1:])) if len(ck_idx) > 1 else np.array([],dtype=np.int)\n",
            "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "100%|██████████| 433/433 [00:00<00:00, 1232112.37B/s]\n",
            "100%|██████████| 435779157/435779157 [00:18<00:00, 23054069.24B/s]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_transformers/modeling_utils.py:539: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(resolved_archive_file, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.532867</td>\n",
              "      <td>2.500130</td>\n",
              "      <td>0.028986</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.487990</td>\n",
              "      <td>2.389054</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.407630</td>\n",
              "      <td>2.217564</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.320046</td>\n",
              "      <td>2.089252</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.218750</td>\n",
              "      <td>1.935261</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.086598</td>\n",
              "      <td>1.626339</td>\n",
              "      <td>0.507246</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.899667</td>\n",
              "      <td>1.318928</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.678859</td>\n",
              "      <td>1.098083</td>\n",
              "      <td>0.724638</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.465765</td>\n",
              "      <td>0.907181</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.258402</td>\n",
              "      <td>0.813511</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.071935</td>\n",
              "      <td>0.751756</td>\n",
              "      <td>0.797101</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.914972</td>\n",
              "      <td>0.731237</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.788467</td>\n",
              "      <td>0.714716</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.683331</td>\n",
              "      <td>0.705936</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.598488</td>\n",
              "      <td>0.703807</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.535659</td>\n",
              "      <td>0.702709</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/text/data.py:124: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  sort_idx = np.concatenate(np.random.permutation(ck_idx[1:])) if len(ck_idx) > 1 else np.array([],dtype=np.int)\n",
            "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='93' class='' max='93' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [93/93 00:01&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A    1.00000   1.00000   1.00000         5\n",
            "          FT    0.00000   0.00000   0.00000         2\n",
            "           L    1.00000   0.33333   0.50000         3\n",
            "          LF    1.00000   0.80000   0.88889        10\n",
            "          MN    0.00000   0.00000   0.00000         4\n",
            "           O    0.83333   0.93750   0.88235        16\n",
            "          PE    0.84615   0.78571   0.81481        14\n",
            "          SC    0.75000   0.60000   0.66667         5\n",
            "          SE    0.77273   1.00000   0.87179        17\n",
            "          US    0.72727   0.94118   0.82051        17\n",
            "\n",
            "    accuracy                        0.81720        93\n",
            "   macro avg    0.69295   0.63977   0.64450        93\n",
            "weighted avg    0.77881   0.81720   0.78512        93\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Memory usage: 1320.96 MB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "metadata": {
        "id": "sqGyLEubBw60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "337cada8-c2bd-4e0e-8ef6-dd98f0e26f43"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "#@title Define function to calculate averaged metric results {display-mode: \"form\"}\n",
        "def calcAverageMetrics(results):\n",
        "  precisions, recalls, fscores = [], [], []\n",
        "  for i in range(int(len(results)/4)):\n",
        "    precisions.append(results[i*4])\n",
        "    recalls.append(results[i*4+1])\n",
        "    fscores.append(results[i*4+2])\n",
        "  precision = [0]*len(precisions[0])\n",
        "  recall = [0]*len(recalls[0])\n",
        "  fscore = [0]*len(fscores[0])\n",
        "  for i in range(len(precisions)):\n",
        "    precision = precision + precisions[i]\n",
        "    recall = recall + recalls[i]\n",
        "    fscore = fscore + fscores[i]\n",
        "  precision = precision / int(len(results)/4)\n",
        "  recall = recall / int(len(results)/4)\n",
        "  fscore = fscore / int(len(results)/4)\n",
        "  return precision, recall, fscore"
      ],
      "outputs": [],
      "metadata": {
        "id": "ya_eGZs2Pl1h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "#@title Display overall results and log them {display-mode: \"form\"}\n",
        "target_names = []\n",
        "test_labels = df[config_data.label_column].unique()\n",
        "\n",
        "test_labels = np.sort(test_labels)\n",
        "for x in test_labels:\n",
        "  target_names.append(label_indices.get(x))\n",
        "\n",
        "print('/////////////////////// Aggregated Predictions Result /////////////////////////////')\n",
        "logResult('/////////////////////// Aggregated Predictions Result /////////////////////////////')\n",
        "result = classification_report(overall_flat_true_labels, overall_flat_predictions, target_names=target_names, digits = 5)\n",
        "logResult(result)\n",
        "print(result)\n",
        "print('/////////////////////// Averaged Metrics Result /////////////////////////////')\n",
        "logResult('/////////////////////// Averaged Metrics Result /////////////////////////////')\n",
        "precision, recall, fscore = calcAverageMetrics(results)\n",
        "print(\"              precision    recall  f1-score\")\n",
        "logResult(\"              precision    recall  f1-score\")\n",
        "for i in range(len(precision)):\n",
        "  print('{:<14}'.format(target_names[i]) + '  {:.5f}'.format(precision[i]) + '   {:.5f}'.format(recall[i]) + '   {:.5f}'.format(fscore[i]))\n",
        "  logResult('{:<14}'.format(target_names[i]) + '  {:.5f}'.format(precision[i]) + '   {:.5f}'.format(recall[i]) + '   {:.5f}'.format(fscore[i]))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/////////////////////// Aggregated Predictions Result /////////////////////////////\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A    1.00000   1.00000   1.00000         5\n",
            "          FT    0.00000   0.00000   0.00000         2\n",
            "           L    1.00000   0.33333   0.50000         3\n",
            "          LF    1.00000   0.80000   0.88889        10\n",
            "          MN    0.00000   0.00000   0.00000         4\n",
            "           O    0.83333   0.93750   0.88235        16\n",
            "          PE    0.84615   0.78571   0.81481        14\n",
            "          SC    0.75000   0.60000   0.66667         5\n",
            "          SE    0.77273   1.00000   0.87179        17\n",
            "          US    0.72727   0.94118   0.82051        17\n",
            "\n",
            "    accuracy                        0.81720        93\n",
            "   macro avg    0.69295   0.63977   0.64450        93\n",
            "weighted avg    0.77881   0.81720   0.78512        93\n",
            "\n",
            "/////////////////////// Averaged Metrics Result /////////////////////////////\n",
            "              precision    recall  f1-score\n",
            "A               1.00000   1.00000   1.00000\n",
            "FT              0.00000   0.00000   0.00000\n",
            "L               1.00000   0.33333   0.50000\n",
            "LF              1.00000   0.80000   0.88889\n",
            "MN              0.00000   0.00000   0.00000\n",
            "O               0.83333   0.93750   0.88235\n",
            "PE              0.84615   0.78571   0.81481\n",
            "SC              0.75000   0.60000   0.66667\n",
            "SE              0.77273   1.00000   0.87179\n",
            "US              0.72727   0.94118   0.82051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "metadata": {
        "id": "DF7kkSziMjYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2427d3-8dfb-4fca-f0d7-bffe632dab1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "UeoCn0Bs-Wds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "#@title Save the model along with its config\n",
        "def create_model_name():\n",
        "    name = 'NoRBERT_{clasz}_e{epochs}_{sampling}'.format(clasz=clazz, epochs=str(config.epochs),sampling=\"NoSampling\")\n",
        "    return name\n",
        "\n",
        "def save_config(model_save_path, model_name):\n",
        "    settings = ''\n",
        "    for item in config.__dict__:\n",
        "        value = config[item]\n",
        "        setting = '{item}={value},\\n'.format(item=item, value=value)\n",
        "        settings += setting\n",
        "    save_path = model_save_path + model_name + '.config'\n",
        "    with open(save_path, 'w', encoding='utf-8') as out:\n",
        "        out.write(settings)\n",
        "\n",
        "# make it flase if you want to unsave the trained model\n",
        "if True:\n",
        "    model_name = create_model_name()\n",
        "    model_save_path = config_data.root_folder + config_data.model_path\n",
        "    if not os.path.isdir(model_save_path):\n",
        "      print(\"Models folder does not exist, trying to create folder.\")\n",
        "      try:\n",
        "        os.mkdir(model_save_path)\n",
        "      except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % model_save_path)\n",
        "      else:\n",
        "        print (\"Successfully created the directory %s\" % model_save_path)\n",
        "    save_config(model_save_path, model_name)\n",
        "    model_save_file = model_save_path + model_name + '.pkl'\n",
        "    classifier.export(file = model_save_file)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models folder does not exist, trying to create folder.\n",
            "Successfully created the directory ./models/\n"
          ]
        }
      ],
      "metadata": {
        "id": "DXTWGILJ4kJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02413c6-af57-4796-8506-28dd5f40dd1a"
      }
    }
  ]
}